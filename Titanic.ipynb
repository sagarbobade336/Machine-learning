{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1246ca0f-e353-48f8-8410-83310cd0b305",
   "metadata": {},
   "source": [
    "# 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c0da40ef-c117-4899-92d5-7c6e8410141a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2438057-cb0e-4076-9ba7-a28cc09aca93",
   "metadata": {},
   "source": [
    "# 2. Load and prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2c0edc6e-304b-49a1-9f03-0066ed321725",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Pclass     Sex   Age  SibSp  Parch     Fare Embarked  Survived\n",
      "0       3    male  22.0      1      0   7.2500        S         0\n",
      "1       1  female  38.0      1      0  71.2833        C         1\n",
      "2       3  female  26.0      0      0   7.9250        S         1\n",
      "3       1  female  35.0      1      0  53.1000        S         1\n",
      "4       3    male  35.0      0      0   8.0500        S         0\n"
     ]
    }
   ],
   "source": [
    "# load dataset\n",
    "df=pd.read_csv(\"Downloads/archive (2)/titanic.csv\")\n",
    "\n",
    "# select relevant features\n",
    "features =[\"Pclass\",\"Sex\",\"Age\",\"SibSp\",\"Parch\",\"Fare\",\"Embarked\"]\n",
    "df=df[features+[\"Survived\"]].dropna()  # Drop rows with missing values\n",
    "\n",
    "# Dispaly the first few rows\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133066ee-9a38-4f37-9120-77561c05763f",
   "metadata": {},
   "source": [
    "# 3.Define Preprocessing Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "323ef76b-8953-4198-bda2-0ff9730c8f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define numerical and categorical features\n",
    "num_features = ['Age', 'SibSp', 'Parch', 'Fare']\n",
    "cat_features = ['Pclass', 'Sex', 'Embarked']\n",
    "\n",
    "# Define transformers\n",
    "num_transformer = StandardScaler()  # Standardization for numerical features\n",
    "cat_transformer = OneHotEncoder(handle_unknown='ignore')  # One-hot encoding for categorical features\n",
    "\n",
    "# Combine transformers into a preprocessor\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', num_transformer, num_features),\n",
    "    ('cat', cat_transformer, cat_features)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca210f48-559d-4cc3-a63e-eb804e16d462",
   "metadata": {},
   "source": [
    "# 4.Split the data for training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "41f9c996-3fa3-49db-86be-4b1e0a21a7a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (569, 7)\n",
      "Testing set shape: (143, 7)\n"
     ]
    }
   ],
   "source": [
    "# Define target and features\n",
    "X = df[features]\n",
    "y = df['Survived']\n",
    "\n",
    "# Split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Display the shape of the data\n",
    "print(f\"Training set shape: {X_train.shape}\")\n",
    "print(f\"Testing set shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63939655-0249-4c58-b1f7-e68bfc68493a",
   "metadata": {},
   "source": [
    "# 5. Build and Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "52509445-e4d4-4f67-9b88-23bb246d8b95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training complete!\n"
     ]
    }
   ],
   "source": [
    "# Define the pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),  # Data transformation\n",
    "    ('classifier', RandomForestClassifier(n_estimators=100, random_state=42))  # ML model\n",
    "])\n",
    "\n",
    "# Train the model\n",
    "pipeline.fit(X_train, y_train)\n",
    "print(\"Model training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea2fc0b1-1ef6-41f3-9657-5b4314c37c4a",
   "metadata": {},
   "source": [
    "# 6. Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6a2c7f94-2208-4082-bc3c-29c8a019eca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.76\n"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Compute accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Model Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e21a336-373a-4b11-824f-544aa6335357",
   "metadata": {},
   "source": [
    "# 7. Save and Load the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7e4630fc-826b-47c1-9f34-4a7c3b58a0ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: Did not Survive\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the trained pipeline\n",
    "joblib.dump(pipeline, 'ml_pipeline.pkl')\n",
    "\n",
    "# Load the model\n",
    "loaded_pipeline = joblib.load('ml_pipeline.pkl')\n",
    "\n",
    "# Predict using the loaded model\n",
    "sample_data = pd.DataFrame([{'Pclass': 3, 'Sex': 'male', 'Age': 25, 'SibSp': 0, 'Parch': 0, 'Fare': 7.5, 'Embarked': 'S'}])\n",
    "prediction = loaded_pipeline.predict(sample_data)\n",
    "print(f\"Prediction: {'Survived' if prediction[0] == 1 else 'Did not Survive'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49cb3c3c-76d4-49bd-972e-deb0b92441f2",
   "metadata": {},
   "source": [
    "**Conclusion**\r\n",
    "To sum it up, a machine pipeline simplifies and automates the complex process of developing AI models, ensuring efficiency, accuracy and scalability. By integrating structured steps like data preprocessing, model training, evaluation and deployment, it streamlines machine learning workflows. With the growing demand for AI-driven insights, ML pipelines will continue to be a key enabler of innovation and making machine learning faster and more applicable to real world challenges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9914d2ab-dd87-41f7-9f95-388f52a5000e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
